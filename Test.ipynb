{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9091b19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'faces' already exists.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import face_recognition\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import subprocess\n",
    "import fil1\n",
    "import os\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_registration_program():\n",
    "    registration_program = \"python3 register.py\"  # Replace with the command to run your register.py program\n",
    "    subprocess.Popen(registration_program, shell=True)\n",
    "# Define constants\n",
    "EYE_AR_THRESH = 0.2\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "\n",
    "# Initialize the frame counters and the total number of blinks\n",
    "COUNTER = 0\n",
    "TOTAL = 0\n",
    "def eye_aspect_ratio(eye):\n",
    "    # Compute the euclidean distances between the two sets of vertical eye landmarks (x, y)-coordinates\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "\n",
    "    # Compute the euclidean distance between the horizontal eye landmark (x, y)-coordinates\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "\n",
    "    # Compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "\n",
    "    # Return the eye aspect ratio\n",
    "    return ear\n",
    "\n",
    "# Initialize dlib face detector and facial landmark predictor\n",
    "def run_recognition():\n",
    "    \n",
    "    file_path = '/home/parthjoshi/Desktop/webside/face_detection/Face_recognition/shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(file_path)\n",
    "   \n",
    "\n",
    "    # Initialize lists for known face encodings and names\n",
    "    previous_landmarks = None\n",
    "    liveness_threshold = 5\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    # Directory containing face images\n",
    "    directory = fil1.faces_directory  # Replace with the path to your directory\n",
    "\n",
    "    # Load known faces and encodings from directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            name = os.path.splitext(filename)[0]\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # Detect face landmarks\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            face_locations = face_recognition.face_locations(rgb)\n",
    "            if len(face_locations) > 0:\n",
    "                face_location = face_locations[0]\n",
    "                top, right, bottom, left = face_location\n",
    "\n",
    "                # Perform face encoding\n",
    "                face_encoding = face_recognition.face_encodings(rgb, [face_location])[0]\n",
    "\n",
    "                # Add face encoding and name to the lists\n",
    "                known_faces.append(face_encoding)\n",
    "                known_names.append(name)\n",
    "\n",
    "    # Initialize video capture\n",
    "    cap = cv2.VideoCapture(0)  # Replace with your video source if not using the webcam\n",
    "\n",
    "    # Get screen resolution\n",
    "    screen_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    screen_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "    # Calculate ROI dimensions\n",
    "    roi_width = int(screen_width / 2)\n",
    "    roi_height = int(screen_height / 2)\n",
    "    roi_x = int((screen_width - roi_width) / 2)\n",
    "    roi_y = int((screen_height - roi_height) / 2)\n",
    "\n",
    "    # Initialize tolerance for face recognition (confidence factor)\n",
    "    tolerance = 0.5  # Adjust this value as needed\n",
    "\n",
    "    # Initialize dictionary to track last detected time for recognized faces and unregistered faces\n",
    "    recognized_last_detected = {}\n",
    "    unregistered_last_detected = {}\n",
    "\n",
    "    # Create resizable window\n",
    "    cv2.namedWindow(\"Face Recognition\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Face Recognition\", int(screen_width), int(screen_height))\n",
    "\n",
    "    # Initialize variables for motion detection\n",
    "    prev_frame_gray = None\n",
    "    stationary_counter = 0\n",
    "    \n",
    "    # Eye aspect ratio thresholds and counters\n",
    "    EYE_AR_THRESH = 0.2\n",
    "    EYE_AR_CONSEC_FRAMES = 3\n",
    "    COUNTER = 0\n",
    "    TOTAL_BLINKS = 0\n",
    "\n",
    "    # Main loop\n",
    "    while True:\n",
    "        # Read a frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert frame to gray for motion detection\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        frame_gray = cv2.GaussianBlur(frame_gray, (21, 21), 0)\n",
    "\n",
    "        # Initialize previous frame if it's the first iteration\n",
    "        if prev_frame_gray is None:\n",
    "            prev_frame_gray = frame_gray\n",
    "            continue\n",
    "\n",
    "        # Calculate absolute difference between current and previous frames\n",
    "        frame_delta = cv2.absdiff(prev_frame_gray, frame_gray)\n",
    "\n",
    "        # Apply threshold to detect significant intensity differences\n",
    "        threshold = 30\n",
    "        _, frame_threshold = cv2.threshold(frame_delta, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Dilate the thresholded image to fill in holes\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        frame_threshold = cv2.dilate(frame_threshold, kernel, iterations=2)\n",
    "\n",
    "        # Find contours of significant differences\n",
    "        contours, _ = cv2.findContours(frame_threshold.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Convert frame back to RGB for face recognition\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Draw ROI on the frame\n",
    "        cv2.rectangle(frame, (roi_x, roi_y), (roi_x + roi_width, roi_y + roi_height), (0, 0, 255), 2)\n",
    "\n",
    "        # Detect faces in the frame\n",
    "        face_locations = face_recognition.face_locations(rgb)\n",
    "        face_encodings = face_recognition.face_encodings(rgb, face_locations)\n",
    "\n",
    "        # Initialize set to track unregistered face IDs\n",
    "        unregistered_faces = set()\n",
    "\n",
    "        # Iterate over the face encodings\n",
    "        for face_encoding, (top, right, bottom, left) in zip(face_encodings, face_locations):\n",
    "            # Check if the face is completely outside the ROI\n",
    "            if right < roi_x or left > roi_x + roi_width or bottom < roi_y or top > roi_y + roi_height:\n",
    "                # Draw bounding box in gray color\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (128, 128, 128), 2)\n",
    "                continue\n",
    "\n",
    "            # Compare face encodings with known faces\n",
    "            face_distances = face_recognition.face_distance(known_faces, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            face_distance = face_distances[best_match_index]\n",
    "\n",
    "            if face_distance <= tolerance:\n",
    "                name = known_names[best_match_index]\n",
    "                current_time = datetime.now()\n",
    "\n",
    "                if name not in recognized_last_detected or (current_time - recognized_last_detected[name]) >= timedelta(minutes=2):\n",
    "                    recognized_last_detected[name] = current_time\n",
    "                    record_attendance(name, current_time)\n",
    "                else:\n",
    "                    unregistered_faces.add(name)\n",
    "                \n",
    "                landmarks = predictor(rgb, dlib.rectangle(left, top, right, bottom))\n",
    "                \n",
    "                landmarks_np = np.array([[p.x, p.y] for p in landmarks.parts()])\n",
    "\n",
    "                # Get the coordinates for the left and right eye\n",
    "                leftEye = landmarks_np[36:42]\n",
    "                rightEye = landmarks_np[42:48]\n",
    "\n",
    "                # Compute the eye aspect ratio for both eyes\n",
    "                leftEAR = eye_aspect_ratio(leftEye)\n",
    "                rightEAR = eye_aspect_ratio(rightEye)\n",
    "\n",
    "                # Average the eye aspect ratio together for both eyes\n",
    "                ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "                # Check to see if the eye aspect ratio is below the blink threshold\n",
    "                if ear < EYE_AR_THRESH:\n",
    "                    COUNTER += 1\n",
    "                else:\n",
    "                    if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                        TOTAL_BLINKS += 1\n",
    "                    COUNTER = 0\n",
    "\n",
    "                # Draw the computed eye aspect ratio and the number of blinks on the frame\n",
    "                cv2.putText(frame, \"Blinks: {}\".format(TOTAL_BLINKS), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (300, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                #cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "                #cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                \n",
    "            else:\n",
    "                # Draw bounding box for unknown face in gray color within ROI\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (128, 128, 128), 2)\n",
    "                cv2.putText(frame, \"Unregistered\", (left, bottom + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (128, 128, 128), 2)\n",
    "                unregistered_faces.add(\"Unregistered\")\n",
    "\n",
    "        # Record attendance for unregistered faces if there is motion\n",
    "        current_time = datetime.now()\n",
    "        motion_detected = len(contours) > 0\n",
    "        if motion_detected:\n",
    "            stationary_counter = 0\n",
    "            for name in unregistered_faces:\n",
    "                if name not in unregistered_last_detected or (current_time - unregistered_last_detected[name]) >= timedelta(minutes=1):\n",
    "                    unregistered_last_detected[name] = current_time\n",
    "                    record_attendance(name, current_time)\n",
    "        else:\n",
    "            stationary_counter += 1\n",
    "            if stationary_counter >= 30:\n",
    "                unregistered_faces.clear()\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "        # Check for keyboard interrupt\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('r'):  # Check for 'r' key press\n",
    "            run_registration_program()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Release the video capture and destroy windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def record_attendance(name, current_time):\n",
    "    date_str = current_time.strftime(\"%Y-%m-%d\")\n",
    "    csv_filename = f\"{date_str}.csv\"\n",
    "\n",
    "    # Check if the CSV file already exists\n",
    "    if not os.path.isfile(csv_filename):\n",
    "        with open(csv_filename, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"Time\"])\n",
    "\n",
    "    # Append the attendance entry to the CSV file\n",
    "    with open(csv_filename, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([name, current_time.strftime(\"%H:%M:%S\")])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    run_recognition()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb6d006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import face_recognition\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import subprocess\n",
    "from scipy.spatial import distance as dist\n",
    "import fil1\n",
    "\n",
    "def run_registration_program():\n",
    "    registration_program = \"python3 register.py\"  # Replace with the command to run your register.py program\n",
    "    subprocess.Popen(registration_program, shell=True)\n",
    "\n",
    "# Function to calculate the eye aspect ratio (EAR)\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "def run_recognition():\n",
    "    file_path = '/home/parthjoshi/Desktop/webside/face_detection/Face_recognition/shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(file_path)\n",
    "\n",
    "    # Initialize lists for known face encodings and names\n",
    "    previous_landmarks = None\n",
    "    liveness_threshold = 5\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    # Directory containing face imagescord\n",
    "    directory = fil1.faces_directory  # Replace with the path to your directory\n",
    "\n",
    "    # Load known faces and encodings from directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            name = os.path.splitext(filename)[0]\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # Detect face landmarks\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            face_locations = face_recognition.face_locations(rgb)\n",
    "            if len(face_locations) > 0:\n",
    "                face_location = face_locations[0]\n",
    "                top, right, bottom, left = face_location\n",
    "\n",
    "                # Perform face encoding\n",
    "                face_encoding = face_recognition.face_encodings(rgb, [face_location])[0]\n",
    "\n",
    "                # Add face encoding and name to the lists\n",
    "                known_faces.append(face_encoding)\n",
    "                known_names.append(name)\n",
    "\n",
    "    # Initialize video capture\n",
    "    cap = cv2.VideoCapture(0)  # Replace with your video source if not using the webcam\n",
    "\n",
    "    # Get screen resolution\n",
    "    screen_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    screen_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "    # Calculate ROI dimensions\n",
    "    roi_width = int(screen_width / 2)\n",
    "    roi_height = int(screen_height / 2)\n",
    "    roi_x = int((screen_width - roi_width) / 2)\n",
    "    roi_y = int((screen_height - roi_height) / 2)\n",
    "\n",
    "    # Initialize tolerance for face recognition (confidence factor)\n",
    "    tolerance = 0.5  # Adjust this value as needed\n",
    "\n",
    "    # Initialize dictionary to track last detected time for recognized faces and unregistered faces\n",
    "    recognized_last_detected = {}\n",
    "    unregistered_last_detected = {}\n",
    "\n",
    "    # Create resizable window\n",
    "    cv2.namedWindow(\"Face Recognition\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Face Recognition\", int(screen_width), int(screen_height))\n",
    "\n",
    "    # Initialize variables for motion detection\n",
    "    prev_frame_gray = None\n",
    "    stationary_counter = 0\n",
    "\n",
    "    # Initialize blink detection parameters\n",
    "    EYE_AR_THRESH = 0.2\n",
    "    EYE_AR_CONSEC_FRAMES = 3\n",
    "    blink_counter = 0\n",
    "    blink_detected = False\n",
    "\n",
    "    # Main loop\n",
    "    while True:\n",
    "        # Read a frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert frame to gray for motion detection\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        frame_gray = cv2.GaussianBlur(frame_gray, (21, 21), 0)\n",
    "\n",
    "        # Initialize previous frame if it's the first iteration\n",
    "        if prev_frame_gray is None:\n",
    "            prev_frame_gray = frame_gray\n",
    "            continue\n",
    "\n",
    "        # Calculate absolute difference between current and previous frames\n",
    "        frame_delta = cv2.absdiff(prev_frame_gray, frame_gray)\n",
    "\n",
    "        # Apply threshold to detect significant intensity differences\n",
    "        threshold = 30\n",
    "        _, frame_threshold = cv2.threshold(frame_delta, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Dilate the thresholded image to fill in holes\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        frame_threshold = cv2.dilate(frame_threshold, kernel, iterations=2)\n",
    "\n",
    "        # Find contours of significant differences\n",
    "        contours, _ = cv2.findContours(frame_threshold.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Convert frame back to RGB for face recognition\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Draw ROI on the frame\n",
    "        cv2.rectangle(frame, (roi_x, roi_y), (roi_x + roi_width, roi_y + roi_height), (0, 0, 255), 2)\n",
    "\n",
    "        # Detect faces in the frame\n",
    "        face_locations = face_recognition.face_locations(rgb)\n",
    "        face_encodings = face_recognition.face_encodings(rgb, face_locations)\n",
    "\n",
    "        # Initialize set to track unregistered face IDs\n",
    "        unregistered_faces = set()\n",
    "\n",
    "        # Iterate over the face encodings\n",
    "        for face_encoding, (top, right, bottom, left) in zip(face_encodings, face_locations):\n",
    "            # Check if the face is completely outside the ROI\n",
    "            if right < roi_x or left > roi_x + roi_width or bottom < roi_y or top > roi_y + roi_height:\n",
    "                # Draw bounding box in gray color\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (128, 128, 128), 2)\n",
    "                continue\n",
    "\n",
    "            # Compare face encodings with known faces\n",
    "            face_distances = face_recognition.face_distance(known_faces, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            face_distance = face_distances[best_match_index]\n",
    "\n",
    "            if face_distance <= tolerance:\n",
    "                name = known_names[best_match_index]\n",
    "                current_time = datetime.now()\n",
    "\n",
    "                if name not in recognized_last_detected or (current_time - recognized_last_detected[name]) >= timedelta(minutes=2):\n",
    "                    recognized_last_detected[name] = current_time\n",
    "                    record_attendance(name, current_time)\n",
    "\n",
    "                # Detect eye landmarks\n",
    "                landmarks = predictor(rgb, dlib.rectangle(left, top, right, bottom))\n",
    "                left_eye = np.array([(landmarks.part(36).x, landmarks.part(36).y),\n",
    "                                     (landmarks.part(37).x, landmarks.part(37).y),\n",
    "                                     (landmarks.part(38).x, landmarks.part(38).y),\n",
    "                                     (landmarks.part(39).x, landmarks.part(39).y),\n",
    "                                     (landmarks.part(40).x, landmarks.part(40).y),\n",
    "                                     (landmarks.part(41).x, landmarks.part(41).y)], np.int32)\n",
    "                right_eye = np.array([(landmarks.part(42).x, landmarks.part(42).y),\n",
    "                                      (landmarks.part(43).x, landmarks.part(43).y),\n",
    "                                      (landmarks.part(44).x, landmarks.part(44).y),\n",
    "                                      (landmarks.part(45).x, landmarks.part(45).y),\n",
    "                                      (landmarks.part(46).x, landmarks.part(46).y),\n",
    "                                      (landmarks.part(47).x, landmarks.part(47).y)], np.int32)\n",
    "\n",
    "                left_ear = eye_aspect_ratio(left_eye)\n",
    "                right_ear = eye_aspect_ratio(right_eye)\n",
    "\n",
    "                # Average the EAR for both eyes\n",
    "                ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "                # Check if EAR is below the blink threshold\n",
    "                if ear < EYE_AR_THRESH:\n",
    "                    blink_counter += 1\n",
    "                else:\n",
    "                    if blink_counter >= EYE_AR_CONSEC_FRAMES:\n",
    "                        blink_detected = True\n",
    "                    blink_counter = 0\n",
    "\n",
    "                # Draw bounding box and display name on the frame\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                if blink_detected:\n",
    "                    cv2.putText(frame, \"Blink Detected\", (left, top - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                    blink_detected = False\n",
    "            else:\n",
    "                # Draw bounding box for unknown face in gray color within ROI\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (128, 128, 128), 2)\n",
    "                cv2.putText(frame, \"Unregistered\", (left, bottom + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (128, 128, 128), 2)\n",
    "                unregistered_faces.add(\"Unregistered\")\n",
    "\n",
    "        # Record attendance for unregistered faces if there is motion\n",
    "        current_time = datetime.now()\n",
    "        motion_detected = len(contours) > 0\n",
    "        if motion_detected:\n",
    "            stationary_counter = 0\n",
    "            for name in unregistered_faces:\n",
    "                if name not in unregistered_last_detected or (current_time - unregistered_last_detected[name]) >= timedelta(minutes=1):\n",
    "                    unregistered_last_detected[name] = current_time\n",
    "                    record_attendance(name, current_time)\n",
    "        else:\n",
    "            stationary_counter += 1\n",
    "            if stationary_counter >= 30:\n",
    "                unregistered_faces.clear()\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "        # Check for keyboard interrupt\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('r'):  # Check for 'r' key press\n",
    "            run_registration_program()\n",
    "\n",
    "    # Release the video capture and destroy windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def record_attendance(name, current_time):\n",
    "    date_str = current_time.strftime(\"%Y-%m-%d\")\n",
    "    csv_filename = f\"{date_str}.csv\"\n",
    "\n",
    "    # Check if the CSV file already exists\n",
    "    if not os.path.isfile(csv_filename):\n",
    "        with open(csv_filename, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"Time\"])\n",
    "\n",
    "    # Append the attendance entry to the CSV file\n",
    "    with open(csv_filename, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([name, current_time.strftime(\"%H:%M:%S\")])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_recognition()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ff39b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'faces' already exists.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import face_recognition\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import subprocess\n",
    "import fil1\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def run_registration_program():\n",
    "    registration_program = \"python3 register.py\"  # Replace with the command to run your register.py program\n",
    "    subprocess.Popen(registration_program, shell=True)\n",
    "# Initialize dlib face detector and facial landmark predictor\n",
    "def run_recognition():\n",
    "    \n",
    "    file_path = '/home/parthjoshi/Desktop/webside/face_detection/Face_recognition/shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(file_path)\n",
    "   \n",
    "\n",
    "    # Initialize lists for known face encodings and names\n",
    "    previous_landmarks = None\n",
    "    liveness_threshold = 5\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    # Directory containing face imagescord\n",
    "    directory = fil1.faces_directory  # Replace with the path to your directory\n",
    "\n",
    "    # Load known faces and encodings from directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            name = os.path.splitext(filename)[0]\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # Detect face landmarks\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            face_locations = face_recognition.face_locations(rgb)\n",
    "            if len(face_locations) > 0:\n",
    "                face_location = face_locations[0]\n",
    "                top, right, bottom, left = face_location\n",
    "\n",
    "                # Perform face encoding\n",
    "                face_encoding = face_recognition.face_encodings(rgb, [face_location])[0]\n",
    "\n",
    "                # Add face encoding and name to the lists\n",
    "                known_faces.append(face_encoding)\n",
    "                known_names.append(name)\n",
    "\n",
    "    # Initialize video capture\n",
    "    cap = cv2.VideoCapture(0)  # Replace with your video source if not using the webcam\n",
    "\n",
    "    # Get screen resolution\n",
    "    screen_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    screen_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "    # Calculate ROI dimensions\n",
    "    roi_width = int(screen_width / 2)\n",
    "    roi_height = int(screen_height / 2)\n",
    "    roi_x = int((screen_width - roi_width) / 2)\n",
    "    roi_y = int((screen_height - roi_height) / 2)\n",
    "\n",
    "    # Initialize tolerance for face recognition (confidence factor)\n",
    "    tolerance = 0.5  # Adjust this value as needed\n",
    "\n",
    "    # Initialize dictionary to track last detected time for recognized faces and unregistered faces\n",
    "    recognized_last_detected = {}\n",
    "    unregistered_last_detected = {}\n",
    "\n",
    "    # Create resizable window\n",
    "    cv2.namedWindow(\"Face Recognition\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Face Recognition\", int(screen_width), int(screen_height))\n",
    "\n",
    "    # Initialize variables for motion detection\n",
    "    prev_frame_gray = None\n",
    "    stationary_counter = 0\n",
    "\n",
    "    # Main loop\n",
    "    while True:\n",
    "        # Read a frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert frame to gray for motion detection\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        frame_gray = cv2.GaussianBlur(frame_gray, (21, 21), 0)\n",
    "\n",
    "        # Initialize previous frame if it's the first iteration\n",
    "        if prev_frame_gray is None:\n",
    "            prev_frame_gray = frame_gray\n",
    "            continue\n",
    "\n",
    "        # Calculate absolute difference between current and previous frames\n",
    "        frame_delta = cv2.absdiff(prev_frame_gray, frame_gray)\n",
    "\n",
    "        # Apply threshold to detect significant intensity differences\n",
    "        threshold = 30\n",
    "        _, frame_threshold = cv2.threshold(frame_delta, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Dilate the thresholded image to fill in holes\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        frame_threshold = cv2.dilate(frame_threshold, kernel, iterations=2)\n",
    "\n",
    "        # Find contours of significant differences\n",
    "        contours, _ = cv2.findContours(frame_threshold.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Convert frame back to RGB for face recognition\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Draw ROI on the frame\n",
    "        cv2.rectangle(frame, (roi_x, roi_y), (roi_x + roi_width, roi_y + roi_height), (0, 0, 255), 2)\n",
    "\n",
    "        # Detect faces in the frame\n",
    "        face_locations = face_recognition.face_locations(rgb)\n",
    "        face_encodings = face_recognition.face_encodings(rgb, face_locations)\n",
    "\n",
    "        # Initialize set to track unregistered face IDs\n",
    "        unregistered_faces = set()\n",
    "\n",
    "        # Iterate over the face encodings\n",
    "        for face_encoding, (top, right, bottom, left) in zip(face_encodings, face_locations):\n",
    "            # Check if the face is completely outside the ROI\n",
    "            if right < roi_x or left > roi_x + roi_width or bottom < roi_y or top > roi_y + roi_height:\n",
    "                # Draw bounding box in gray color\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (128, 128, 128), 2)\n",
    "                continue\n",
    "\n",
    "            # Compare face encodings with known faces\n",
    "            face_distances = face_recognition.face_distance(known_faces, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            face_distance = face_distances[best_match_index]\n",
    "\n",
    "            if face_distance <= tolerance:\n",
    "                name = known_names[best_match_index]\n",
    "                current_time = datetime.now()\n",
    "\n",
    "                if name not in recognized_last_detected or (current_time - recognized_last_detected[name]) >= timedelta(minutes=2):\n",
    "                    recognized_last_detected[name] = current_time\n",
    "                    record_attendance(name, current_time)\n",
    "                else:\n",
    "                    unregistered_faces.add(name)\n",
    "                \n",
    "                landmarks = predictor(rgb, dlib.rectangle(left, top, right, bottom))\n",
    "                \n",
    "\n",
    "                # Draw bounding box and display name on the frame\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            else:\n",
    "                # Draw bounding box for unknown face in gray color within ROI\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (128, 128, 128), 2)\n",
    "                cv2.putText(frame, \"Unregistered\", (left, bottom + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (128, 128, 128), 2)\n",
    "                unregistered_faces.add(\"Unregistered\")\n",
    "\n",
    "        # Record attendance for unregistered faces if there is motion\n",
    "        current_time = datetime.now()\n",
    "        motion_detected = len(contours) > 0\n",
    "        if motion_detected:\n",
    "            stationary_counter = 0\n",
    "            for name in unregistered_faces:\n",
    "                if name not in unregistered_last_detected or (current_time - unregistered_last_detected[name]) >= timedelta(minutes=1):\n",
    "                    unregistered_last_detected[name] = current_time\n",
    "                    record_attendance(name, current_time)\n",
    "        else:\n",
    "            stationary_counter += 1\n",
    "            if stationary_counter >= 30:\n",
    "                unregistered_faces.clear()\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "        # Check for keyboard interrupt\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('r'):  # Check for 'r' key press\n",
    "            run_registration_program()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Release the video capture and destroy windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def record_attendance(name, current_time):\n",
    "    date_str = current_time.strftime(\"%Y-%m-%d\")\n",
    "    csv_filename = f\"{date_str}.csv\"\n",
    "\n",
    "    # Check if the CSV file already exists\n",
    "    if not os.path.isfile(csv_filename):\n",
    "        with open(csv_filename, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"Time\"])\n",
    "\n",
    "    # Append the attendance entry to the CSV file\n",
    "    with open(csv_filename, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([name, current_time.strftime(\"%H:%M:%S\")])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_recognition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89ea29d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@28.930] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video1): can't open camera by index\n",
      "[ERROR:0@28.931] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@28.931] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video2): can't open camera by index\n",
      "[ERROR:0@28.931] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@28.931] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video3): can't open camera by index\n",
      "[ERROR:0@28.932] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@28.932] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video4): can't open camera by index\n",
      "[ERROR:0@28.932] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@28.932] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video5): can't open camera by index\n",
      "[ERROR:0@28.933] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@28.933] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video6): can't open camera by index\n",
      "[ERROR:0@28.933] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@28.933] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video7): can't open camera by index\n",
      "[ERROR:0@28.933] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@28.934] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video8): can't open camera by index\n",
      "[ERROR:0@28.934] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@28.934] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video9): can't open camera by index\n",
      "[ERROR:0@28.934] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'faces' already exists.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import tkinter.ttk as ttk\n",
    "from tkinter import messagebox\n",
    "import subprocess\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "class FaceRecognitionUI:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Face Recognition Application\")\n",
    "\n",
    "        # Initialize variables for camera selection\n",
    "        self.cameras = self.get_available_cameras()\n",
    "        self.selected_camera = tk.StringVar()\n",
    "        self.selected_camera.set(self.cameras[0] if self.cameras else \"\")\n",
    "\n",
    "        # Create main frame to hold everything\n",
    "        self.main_frame = tk.Frame(self.root)\n",
    "        self.main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Create frame for face recognition display\n",
    "        self.recognition_frame = tk.Frame(self.main_frame, bd=2, relief=tk.SUNKEN)\n",
    "        self.recognition_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Placeholder for face recognition display (you can replace this with actual recognition display logic)\n",
    "        self.recognition_label = tk.Label(self.recognition_frame, text=\"Face Recognition Display\", font=(\"Arial\", 24))\n",
    "        self.recognition_label.pack(pady=50, padx=50, expand=True)\n",
    "\n",
    "        # Create frame for control buttons\n",
    "        self.control_frame = tk.Frame(self.main_frame, bd=2, relief=tk.RAISED)\n",
    "        self.control_frame.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        # Add buttons to the control frame\n",
    "        self.registration_button = ttk.Button(self.control_frame, text=\"Registration\", command=self.open_registration)\n",
    "        self.registration_button.pack(pady=20, padx=10, fill=tk.X)\n",
    "\n",
    "        self.camera_button = ttk.Button(self.control_frame, text=\"Camera Options\", command=self.show_camera_options)\n",
    "        self.camera_button.pack(pady=20, padx=10, fill=tk.X)\n",
    "\n",
    "        self.stop_button = ttk.Button(self.control_frame, text=\"Stop\", command=self.stop_recognition)\n",
    "        self.stop_button.pack(pady=20, padx=10, fill=tk.X)\n",
    "\n",
    "        # Start the face recognition process\n",
    "        self.start_recognition_process()\n",
    "\n",
    "    def start_recognition_process(self):\n",
    "        # Replace with your actual command to run the Application.py\n",
    "        self.recognition_process = subprocess.Popen([\"python3\", \"Application.py\"])\n",
    "\n",
    "    def open_registration(self):\n",
    "        # Replace with your actual command to run the registration code\n",
    "        subprocess.Popen([\"python3\", \"register.py\"])\n",
    "\n",
    "    def get_available_cameras(self):\n",
    "        # Function to detect available cameras\n",
    "        available_cameras = []\n",
    "        for i in range(10):  # Assume up to 10 cameras\n",
    "            cap = cv2.VideoCapture(i)\n",
    "            if cap.isOpened():\n",
    "                available_cameras.append(f\"Camera {i}\")\n",
    "                cap.release()\n",
    "        return available_cameras\n",
    "\n",
    "    def show_camera_options(self):\n",
    "        if not self.cameras:\n",
    "            messagebox.showinfo(\"No Cameras\", \"No cameras detected.\")\n",
    "            return\n",
    "\n",
    "        camera_dialog = tk.Toplevel(self.root)\n",
    "        camera_dialog.title(\"Camera Options\")\n",
    "\n",
    "        camera_label = tk.Label(camera_dialog, text=\"Select Camera:\")\n",
    "        camera_label.pack(pady=10)\n",
    "\n",
    "        camera_dropdown = ttk.Combobox(camera_dialog, textvariable=self.selected_camera, values=self.cameras, state=\"readonly\")\n",
    "        camera_dropdown.pack(pady=10)\n",
    "\n",
    "        ok_button = ttk.Button(camera_dialog, text=\"OK\", command=camera_dialog.destroy)\n",
    "        ok_button.pack(pady=10)\n",
    "\n",
    "    def stop_recognition(self):\n",
    "        if hasattr(self, 'recognition_process') and self.recognition_process.poll() is None:\n",
    "            self.recognition_process.terminate()\n",
    "            messagebox.showinfo(\"Stopped\", \"Face Recognition process stopped.\")\n",
    "        else:\n",
    "            messagebox.showinfo(\"Not Running\", \"Face Recognition process is not running.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = FaceRecognitionUI(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "439b5870",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6840/2411485163.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mrun_recognition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6840/2411485163.py\u001b[0m in \u001b[0;36mrun_recognition\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# Read a frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# Convert frame to gray for motion detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import face_recognition\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import subprocess\n",
    "from tkinter import Tk, Label, Button, filedialog, messagebox\n",
    "\n",
    "def run_registration_program():\n",
    "    \"\"\"Launches the registration program using a tkinter file dialog.\"\"\"\n",
    "    root = Tk()\n",
    "    root.withdraw()  # Hide the main window\n",
    "\n",
    "    registration_program_path = filedialog.askopenfilename(\n",
    "        title=\"Select Registration Program\",\n",
    "        filetypes=[(\"Python Files\", \"*.py\")])\n",
    "\n",
    "    if registration_program_path:\n",
    "        subprocess.Popen([\"python3\", registration_program_path])\n",
    "    else:\n",
    "        messagebox.showerror(\"Error\", \"No registration program selected.\")\n",
    "\n",
    "def run_recognition():\n",
    "    \"\"\"Performs face recognition with a user-friendly UI.\"\"\"\n",
    "\n",
    "    def update_camera_selection():\n",
    "        \"\"\"Updates the selected camera index based on user input.\"\"\"\n",
    "        global camera_index\n",
    "        camera_index = camera_selection_var.get()\n",
    "        start_button.config(state=\"normal\")  # Enable start button after selection\n",
    "\n",
    "    def start_recognition():\n",
    "        \"\"\"Starts the face recognition process.\"\"\"\n",
    "        stop_button.config(state=\"normal\")  # Enable stop button\n",
    "        start_button.config(state=\"disabled\")  # Disable start button\n",
    "\n",
    "        # Initialize dlib face detector and facial landmark predictor\n",
    "        file_path = '/home/parthjoshi/Desktop/webside/face_detection/Face_recognition/shape_predictor_68_face_landmarks.dat'\n",
    "        detector = dlib.get_frontal_face_detector()\n",
    "        predictor = dlib.shape_predictor(file_path)\n",
    "\n",
    "        # Initialize lists for known face encodings and names\n",
    "        previous_landmarks = None\n",
    "        liveness_threshold = 5\n",
    "        known_faces = []\n",
    "        known_names = []\n",
    "\n",
    "        # Directory containing face images\n",
    "        directory = fil1.faces_directory  # Replace with the path to your directory\n",
    "\n",
    "        # Load known faces and encodings from directory\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                name = os.path.splitext(filename)[0]\n",
    "                image_path = os.path.join(directory, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "\n",
    "                # Detect face landmarks\n",
    "                rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                face_locations = face_recognition.face_locations(rgb)\n",
    "                if len(face_locations) > 0:\n",
    "                    face_location = face_locations[0]\n",
    "                    top, right, bottom, left = face_location\n",
    "\n",
    "                    # Perform face encoding\n",
    "                    face_encoding = face_recognition.face_encodings(rgb, [face_location])[0]\n",
    "\n",
    "                    # Add face encoding and name to the lists\n",
    "                    known_faces.append(face_encoding)\n",
    "                    known_names.append(name)\n",
    "\n",
    "        # Initialize video capture\n",
    "        cap = cv2.VideoCapture(camera_index)\n",
    "\n",
    "        # Get screen resolution\n",
    "        screen_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        screen_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "        # Calculate ROI dimensions\n",
    "        roi_width = int(screen_width / 2)\n",
    "        roi_height = int(screen_height / 2)\n",
    "        roi_x = int((screen_width - roi_width) / 2)\n",
    "        roi_y = int((screen_height - roi_height) / 2)\n",
    "\n",
    "        # Initialize tolerance for face recognition (confidence factor)\n",
    "        tolerance = 0.7  # Adjust this value as needed\n",
    "\n",
    "        # Initialize dictionary to track last detected time for recognized faces and unregistered faces\n",
    "        recognized_last_detected = {}\n",
    "        unregistered_last_detected = {}\n",
    "\n",
    "        # Create resizable window\n",
    "        window_name = \"Face Recognition\"\n",
    "        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow(window_name, int(screen_width), int(screen_height))\n",
    "\n",
    "        # Initialize variables for motion detection\n",
    "        prev_frame_gray = None\n",
    "        stationary_counter = 0\n",
    "\n",
    "        # Main loop\n",
    "    while True:\n",
    "        # Read a frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert frame to gray for motion detection\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        frame_gray = cv2.GaussianBlur(frame_gray, (21, 21), 0)\n",
    "\n",
    "        # Initialize previous frame if it's the first iteration\n",
    "        if prev_frame_gray is None:\n",
    "            prev_frame_gray = frame_gray\n",
    "            continue\n",
    "\n",
    "        # Calculate absolute difference between current and previous frames\n",
    "        frame_delta = cv2.absdiff(prev_frame_gray, frame_gray)\n",
    "\n",
    "        # Apply threshold to detect significant intensity differences\n",
    "        threshold = 30\n",
    "        _, frame_threshold = cv2.threshold(frame_delta, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Dilate the thresholded image to fill in holes\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        frame_threshold = cv2.dilate(frame_threshold, kernel, iterations=2)\n",
    "\n",
    "        # Find contours of significant differences\n",
    "        contours, _ = cv2.findContours(frame_threshold.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Convert frame back to RGB for face recognition\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Draw ROI on the frame\n",
    "        cv2.rectangle(frame, (roi_x, roi_y), (roi_x + roi_width, roi_y + roi_height), (0, 0, 255), 2)\n",
    "\n",
    "        # Detect faces in the frame\n",
    "        face_locations = face_recognition.face_locations(rgb)\n",
    "        face_encodings = face_recognition.face_encodings(rgb, face_locations)\n",
    "\n",
    "        # Initialize set to track unregistered face IDs\n",
    "        unregistered_faces = set()\n",
    "\n",
    "        # Iterate over the face encodings\n",
    "        for face_encoding, (top, right, bottom, left) in zip(face_encodings, face_locations):\n",
    "            # Check if the face is completely outside the ROI\n",
    "            if right < roi_x or left > roi_x + roi_width or bottom < roi_y or top > roi_y + roi_height:\n",
    "                # Draw bounding box in gray color\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (128, 128, 128), 2)\n",
    "                continue\n",
    "\n",
    "            # Compare face encodings with known faces\n",
    "            face_distances = face_recognition.face_distance(known_faces, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            face_distance = face_distances[best_match_index]\n",
    "\n",
    "            if face_distance <= tolerance:\n",
    "                name = known_names[best_match_index]\n",
    "                current_time = datetime.now()\n",
    "\n",
    "                if name not in recognized_last_detected or (current_time - recognized_last_detected[name]) >= timedelta(minutes=2):\n",
    "                    recognized_last_detected[name] = current_time\n",
    "                    record_attendance(name, current_time)\n",
    "                else:\n",
    "                    unregistered_faces.add(name)\n",
    "                \n",
    "                landmarks = predictor(rgb, dlib.rectangle(left, top, right, bottom))\n",
    "                \n",
    "\n",
    "                # Draw bounding box and display name on the frame\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            else:\n",
    "                # Draw bounding box for unknown face in gray color within ROI\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (128, 128, 128), 2)\n",
    "                cv2.putText(frame, \"Unregistered\", (left, bottom + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (128, 128, 128), 2)\n",
    "                unregistered_faces.add(\"Unregistered\")\n",
    "\n",
    "        # Record attendance for unregistered faces if there is motion\n",
    "        current_time = datetime.now()\n",
    "        motion_detected = len(contours) > 0\n",
    "        if motion_detected:\n",
    "            stationary_counter = 0\n",
    "            for name in unregistered_faces:\n",
    "                if name not in unregistered_last_detected or (current_time - unregistered_last_detected[name]) >= timedelta(minutes=1):\n",
    "                    unregistered_last_detected[name] = current_time\n",
    "                    record_attendance(name, current_time)\n",
    "        else:\n",
    "            stationary_counter += 1\n",
    "            if stationary_counter >= 30:\n",
    "                unregistered_faces.clear()\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "        # Check for keyboard interrupt\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('r'):  # Check for 'r' key press\n",
    "            run_registration_program()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Release the video capture and destroy windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def record_attendance(name, current_time):\n",
    "    date_str = current_time.strftime(\"%Y-%m-%d\")\n",
    "    csv_filename = f\"{date_str}.csv\"\n",
    "\n",
    "    # Check if the CSV file already exists\n",
    "    if not os.path.isfile(csv_filename):\n",
    "        with open(csv_filename, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"Time\"])\n",
    "\n",
    "    # Append the attendance entry to the CSV file\n",
    "    with open(csv_filename, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([name, current_time.strftime(\"%H:%M:%S\")])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_recognition()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b19c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
